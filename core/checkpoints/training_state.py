"""
Training State Management Module

Contains functions for managing training state, run IDs, and training mode selection.
Handles the user interface for checkpoint selection and training continuation.
"""

import os
from typing import Dict, List, Optional
from .checkpoint_manager import CheckpointManager


class TrainingState:
    """Manages training state and user interactions."""
    
    def __init__(self):
        self.checkpoint_manager = CheckpointManager()
    
    def get_model_name_from_user(self) -> str:
        """Fragt User nach Modell-Name f√ºr neues Training mit intelligenten Vorschl√§gen."""
        print("\nüè∑Ô∏è  MODELL-NAME F√úR NEUES TRAINING")
        print("=" * 50)

        # Generate intelligent suggestions
        suggestions = self._generate_model_name_suggestions()

        print("üìã VORSCHL√ÑGE (Zahlen w√§hlen oder eigenen Namen eingeben):")
        print("-" * 50)
        for i, suggestion in enumerate(suggestions, 1):
            print(f"{i}. {suggestion['name']} ({suggestion['description']})")

        # Scanne existierende Checkpoint-Namen
        existing_models = set()
        checkpoints = self.checkpoint_manager.scan_checkpoints()
        for cp in checkpoints:
            existing_models.add(cp['model_name'])

        if existing_models:
            print(f"\n‚ö†Ô∏è  Existierende Modelle: {', '.join(sorted(existing_models))}")
            print("W√§hle einen ANDEREN Namen um Konflikte zu vermeiden!")

        while True:
            user_input = input(f"\nW√§hle 1-{len(suggestions)} oder gib eigenen Namen ein: ").strip()

            # Check if user selected a number (suggestion)
            if user_input.isdigit():
                choice = int(user_input)
                if 1 <= choice <= len(suggestions):
                    model_name = suggestions[choice - 1]['name']
                    print(f"‚úÖ Vorschlag gew√§hlt: {model_name}")
                else:
                    print(f"‚ùå Ung√ºltige Auswahl. W√§hle 1-{len(suggestions)} oder gib einen Namen ein.")
                    continue
            else:
                # User entered custom name
                model_name = user_input

            # Basis-Validierung
            if not model_name or not model_name.replace('_', '').replace('-', '').isalnum():
                print("‚ùå Ung√ºltiger Name. Nur Buchstaben, Zahlen, _ und - erlaubt.")
                continue

            # Kollisions-Pr√ºfung
            if model_name in existing_models:
                print(f"‚ùå Modell '{model_name}' existiert bereits! W√§hle einen anderen Namen.")
                continue

            print(f"‚úÖ Name '{model_name}' ist verf√ºgbar.")
            return model_name

    def _generate_model_name_suggestions(self) -> list:
        """Generiert intelligente Modell-Namen-Vorschl√§ge basierend auf Config."""
        from config import model_config, training_config
        from ..utils.cache_registry import load_cache_registry

        suggestions = []

        # Calculate model parameters with tied embeddings
        def calculate_tied_parameters():
            h = model_config.hidden_size
            n = model_config.num_layers
            v = model_config.vocab_size
            i = model_config.intermediate_size

            # Embedding parameters (tied: only one embedding matrix)
            if model_config.tie_word_embeddings:
                embedding_params = v * h  # Only input embeddings
            else:
                embedding_params = 2 * v * h  # Input + output embeddings

            # Transformer layers
            attention_params = 4 * h * h  # q, k, v, o projections
            ff_params = 3 * h * i  # gate, up, down projections
            norm_params = 2 * h  # attention_norm + ffn_norm
            layer_params = attention_params + ff_params + norm_params

            # Total parameters
            total_params = embedding_params + (n * layer_params) + h  # +h for final norm
            return total_params

        # Get parameter count and format
        total_params = calculate_tied_parameters()
        if total_params >= 1e9:
            param_str = f"{total_params / 1e9:.1f}B"
        else:
            param_str = f"{total_params / 1e6:.0f}M"

        # Get dataset info from cache registry
        caches = load_cache_registry()
        dataset_info = "FineWeb"  # Default
        seq_len = training_config.sequence_length

        if caches:
            # Find cache matching sequence length
            for cache in caches:
                if cache['sequence_length'] == seq_len:
                    dataset_info = cache['dataset_name']
                    break

        # Generate suggestions
        base_name = f"{param_str}_{dataset_info}_{seq_len}"

        suggestions.extend([
            {
                'name': base_name,
                'description': f'{param_str} parameters, {dataset_info} dataset, {seq_len} seq_len'
            },
            {
                'name': f"experiment_{base_name}",
                'description': f'Experimental run with {param_str} parameters'
            },
            {
                'name': f"modern_llm_{param_str}",
                'description': f'Modern LLM architecture with {param_str} parameters'
            },
            {
                'name': f"test_{param_str}",
                'description': f'Test run with {param_str} parameters'
            }
        ])

        return suggestions
    
    def display_checkpoint_menu(self, checkpoints: List[Dict]) -> Optional[Dict]:
        """Zeigt verf√ºgbare Checkpoints mit Details."""
        print("\nüìã VERF√úGBARE CHECKPOINTS")
        print("=" * 80)

        if not checkpoints:
            print("Keine Checkpoints gefunden.")
            return None

        for i, cp in enumerate(checkpoints, 1):
            print(f"{i:2d}. {cp['model_name']}_checkpoint_{cp['step']}_run_{cp['run_id']}")
            print(f"     Step: {cp['step']:,} | Loss: {cp['loss']:.4f} | Zeit: {cp['timestamp']}")
            print()

        print("N.  Neues Training starten")
        print("X.  Checkpoint-Management (L√∂schen)")
        print("=" * 80)

        while True:
            choice = input("Auswahl [1-{}, N oder X]: ".format(len(checkpoints))).strip().upper()

            if choice == 'N':
                return None
            elif choice == 'X':
                self.checkpoint_management_menu()
                # Nach Management zur√ºck zum Hauptmenu
                return self.display_checkpoint_menu(self.checkpoint_manager.scan_checkpoints())

            try:
                idx = int(choice) - 1
                if 0 <= idx < len(checkpoints):
                    return checkpoints[idx]
                else:
                    print(f"‚ùå Ung√ºltige Auswahl. Bitte 1-{len(checkpoints)}, N oder X eingeben.")
            except ValueError:
                print(f"‚ùå Ung√ºltige Eingabe. Bitte 1-{len(checkpoints)}, N oder X eingeben.")

    def checkpoint_management_menu(self):
        """Checkpoint-Management Menu f√ºr L√∂schen von Checkpoints und Modellen."""
        print("\nüóëÔ∏è  CHECKPOINT-MANAGEMENT")
        print("=" * 80)

        # Scanne Checkpoints und Modelle
        checkpoints = self.checkpoint_manager.scan_checkpoints()
        trained_models = self._scan_trained_models()

        if not checkpoints and not trained_models:
            print("Keine Checkpoints oder Modelle gefunden.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        print("üìã VERF√úGBARE ITEMS ZUM L√ñSCHEN:")
        print("-" * 80)

        items = []

        # Checkpoints hinzuf√ºgen
        if checkpoints:
            print("üîÑ CHECKPOINTS:")
            for cp in checkpoints:
                items.append({
                    'type': 'checkpoint',
                    'data': cp,
                    'display': f"Checkpoint: {cp['model_name']}_checkpoint_{cp['step']}_run_{cp['run_id']} (Step: {cp['step']:,})"
                })
                print(f"{len(items):2d}. {items[-1]['display']}")
            print()

        # Trained Models hinzuf√ºgen
        if trained_models:
            print("üéØ FERTIGE MODELLE:")
            for model in trained_models:
                items.append({
                    'type': 'model',
                    'data': model,
                    'display': f"Modell: {model['name']} ({model['size']:.1f}MB)"
                })
                print(f"{len(items):2d}. {items[-1]['display']}")
            print()

        print("A.  Alle Checkpoints l√∂schen")
        print("B.  Alle Modelle l√∂schen")
        print("L.  Alle Logs l√∂schen")
        print("C.  Alles l√∂schen (Checkpoints + Modelle + Logs)")
        print("R.  Zur√ºck zum Hauptmenu")
        print("=" * 80)

        while True:
            choice = input(f"Auswahl [1-{len(items)}, A, B, L, C oder R]: ").strip().upper()

            if choice == 'R':
                return
            elif choice == 'A':
                self._delete_all_checkpoints()
                return
            elif choice == 'B':
                self._delete_all_models()
                return
            elif choice == 'L':
                self._delete_all_logs()
                return
            elif choice == 'C':
                self._delete_everything()
                return

            try:
                idx = int(choice) - 1
                if 0 <= idx < len(items):
                    self._delete_single_item(items[idx])
                    return
                else:
                    print(f"‚ùå Ung√ºltige Auswahl. Bitte 1-{len(items)}, A, B, C oder R eingeben.")
            except ValueError:
                print(f"‚ùå Ung√ºltige Eingabe. Bitte 1-{len(items)}, A, B, C oder R eingeben.")

    def _scan_trained_models(self):
        """Scannt verf√ºgbare trainierte Modelle."""
        import os
        models = []
        trained_models_dir = "trained_models"

        if not os.path.exists(trained_models_dir):
            return models

        for item in os.listdir(trained_models_dir):
            model_path = os.path.join(trained_models_dir, item)
            if os.path.isdir(model_path):
                # Berechne Ordnergr√∂√üe
                total_size = 0
                for dirpath, dirnames, filenames in os.walk(model_path):
                    for filename in filenames:
                        filepath = os.path.join(dirpath, filename)
                        if os.path.exists(filepath):
                            total_size += os.path.getsize(filepath)

                models.append({
                    'name': item,
                    'path': model_path,
                    'size': total_size / (1024 * 1024)  # MB
                })

        return sorted(models, key=lambda x: x['name'])

    def _delete_single_item(self, item):
        """L√∂scht ein einzelnes Item (Checkpoint oder Modell) mit zugeh√∂rigen Logs."""
        import os
        import shutil

        # Zeige was gel√∂scht wird (inklusive Logs bei Checkpoints)
        print(f"\n‚ö†Ô∏è  L√ñSCHUNG BEST√ÑTIGEN:")
        print(f"Item: {item['display']}")

        if item['type'] == 'checkpoint':
            # Finde zugeh√∂rige Log-Dateien
            related_logs = self._find_related_logs(item['data'])
            if related_logs:
                print(f"\nüìã ZUGEH√ñRIGE LOGS (werden mit gel√∂scht):")
                for log_file in related_logs:
                    log_size = os.path.getsize(log_file) / 1024 if os.path.exists(log_file) else 0
                    print(f"   ‚Ä¢ {os.path.basename(log_file)} ({log_size:.1f}KB)")

        confirm = input("\nWirklich l√∂schen? [y/N]: ").strip().lower()

        if confirm != 'y':
            print("‚ùå L√∂schung abgebrochen.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        try:
            if item['type'] == 'checkpoint':
                # L√∂sche Checkpoint-Datei
                filepath = item['data']['filepath']
                if os.path.exists(filepath):
                    os.remove(filepath)
                    print(f"‚úÖ Checkpoint gel√∂scht: {os.path.basename(filepath)}")
                else:
                    print(f"‚ö†Ô∏è  Checkpoint-Datei nicht gefunden: {filepath}")

                # L√∂sche zugeh√∂rige Logs
                related_logs = self._find_related_logs(item['data'])
                deleted_logs = 0
                for log_file in related_logs:
                    try:
                        if os.path.exists(log_file):
                            os.remove(log_file)
                            deleted_logs += 1
                            print(f"‚úÖ Log gel√∂scht: {os.path.basename(log_file)}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è  Fehler beim L√∂schen von {os.path.basename(log_file)}: {e}")

                if related_logs:
                    print(f"üìä {deleted_logs}/{len(related_logs)} Log-Dateien gel√∂scht.")

            elif item['type'] == 'model':
                # L√∂sche Modell-Ordner
                model_path = item['data']['path']
                if os.path.exists(model_path):
                    shutil.rmtree(model_path)
                    print(f"‚úÖ Modell gel√∂scht: {item['data']['name']}")
                else:
                    print(f"‚ö†Ô∏è  Modell-Ordner nicht gefunden: {model_path}")

        except Exception as e:
            print(f"‚ùå Fehler beim L√∂schen: {e}")

        input("Dr√ºcke Enter um fortzufahren...")

    def _find_related_logs(self, checkpoint_data):
        """Findet alle Log-Dateien die zu einem Checkpoint geh√∂ren."""
        import os
        import glob

        model_name = checkpoint_data['model_name']
        run_id = checkpoint_data['run_id']

        # M√∂gliche Log-Datei-Patterns
        log_patterns = [
            f"training_logs/{model_name}_run_{run_id}.json",
            f"training_logs/{model_name}_run_{run_id}_summary.json",
            f"training_logs/{model_name}_run_{run_id}_training_plots.png",
            f"training_logs/{model_name}_training_plots.png",  # Ohne run_id
        ]

        related_logs = []
        for pattern in log_patterns:
            # Verwende glob f√ºr flexible Suche
            matches = glob.glob(pattern)
            related_logs.extend(matches)

        # Entferne Duplikate und sortiere
        related_logs = sorted(list(set(related_logs)))

        return related_logs

    def _delete_all_checkpoints(self):
        """L√∂scht alle Checkpoints mit zugeh√∂rigen Logs."""
        import os

        checkpoints = self.checkpoint_manager.scan_checkpoints()
        if not checkpoints:
            print("Keine Checkpoints zum L√∂schen gefunden.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        # Sammle alle zugeh√∂rigen Log-Dateien
        all_related_logs = set()
        for cp in checkpoints:
            related_logs = self._find_related_logs(cp)
            all_related_logs.update(related_logs)

        print(f"\n‚ö†Ô∏è  ALLE CHECKPOINTS L√ñSCHEN:")
        print(f"Checkpoints: {len(checkpoints)}")
        if all_related_logs:
            total_log_size = sum(os.path.getsize(log) for log in all_related_logs if os.path.exists(log)) / 1024
            print(f"Zugeh√∂rige Logs: {len(all_related_logs)} Dateien ({total_log_size:.1f}KB)")

        confirm = input("Wirklich ALLE Checkpoints und Logs l√∂schen? [y/N]: ").strip().lower()

        if confirm != 'y':
            print("‚ùå L√∂schung abgebrochen.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        # L√∂sche Checkpoints
        deleted_checkpoints = 0
        for cp in checkpoints:
            try:
                if os.path.exists(cp['filepath']):
                    os.remove(cp['filepath'])
                    deleted_checkpoints += 1
            except Exception as e:
                print(f"‚ùå Fehler beim L√∂schen von {cp['filename']}: {e}")

        # L√∂sche zugeh√∂rige Logs
        deleted_logs = 0
        for log_file in all_related_logs:
            try:
                if os.path.exists(log_file):
                    os.remove(log_file)
                    deleted_logs += 1
            except Exception as e:
                print(f"‚ö†Ô∏è  Fehler beim L√∂schen von {os.path.basename(log_file)}: {e}")

        print(f"‚úÖ {deleted_checkpoints}/{len(checkpoints)} Checkpoints gel√∂scht.")
        if all_related_logs:
            print(f"‚úÖ {deleted_logs}/{len(all_related_logs)} Log-Dateien gel√∂scht.")

        input("Dr√ºcke Enter um fortzufahren...")

    def _delete_all_models(self):
        """L√∂scht alle trainierten Modelle."""
        import os
        import shutil

        models = self._scan_trained_models()
        if not models:
            print("Keine Modelle zum L√∂schen gefunden.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        total_size = sum(model['size'] for model in models)
        print(f"\n‚ö†Ô∏è  ALLE MODELLE L√ñSCHEN:")
        print(f"Anzahl: {len(models)} Modelle ({total_size:.1f}MB)")
        confirm = input("Wirklich ALLE Modelle l√∂schen? [y/N]: ").strip().lower()

        if confirm != 'y':
            print("‚ùå L√∂schung abgebrochen.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        deleted_count = 0
        for model in models:
            try:
                if os.path.exists(model['path']):
                    shutil.rmtree(model['path'])
                    deleted_count += 1
            except Exception as e:
                print(f"‚ùå Fehler beim L√∂schen von {model['name']}: {e}")

        print(f"‚úÖ {deleted_count}/{len(models)} Modelle gel√∂scht.")
        input("Dr√ºcke Enter um fortzufahren...")

    def _delete_all_logs(self):
        """L√∂scht alle Log-Dateien aus allen Log-Ordnern."""
        import os
        import shutil

        # Alle Log-Ordner definieren
        log_directories = [
            "training_logs",                    # Root-Level (aktuelle Session)
            "LLM_Stuff/training_logs",         # LLM_Stuff-Level (Archiv)
            "current_training/logs",           # Falls vorhanden
            "logs",                            # System-Config default
        ]

        # Sammle alle Log-Dateien
        all_log_files = []
        total_size = 0

        for log_dir in log_directories:
            if os.path.exists(log_dir):
                for item in os.listdir(log_dir):
                    item_path = os.path.join(log_dir, item)
                    if os.path.isfile(item_path):
                        # Nur Log-relevante Dateien
                        if any(item.endswith(ext) for ext in ['.json', '.log', '.png']):
                            file_size = os.path.getsize(item_path)
                            all_log_files.append({
                                'path': item_path,
                                'name': item,
                                'dir': log_dir,
                                'size': file_size
                            })
                            total_size += file_size

        if not all_log_files:
            print("Keine Log-Dateien zum L√∂schen gefunden.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        # Gruppiere nach Ordnern f√ºr bessere √úbersicht
        dirs_with_files = {}
        for log_file in all_log_files:
            dir_name = log_file['dir']
            if dir_name not in dirs_with_files:
                dirs_with_files[dir_name] = []
            dirs_with_files[dir_name].append(log_file)

        print(f"\n‚ö†Ô∏è  ALLE LOGS L√ñSCHEN:")
        print(f"Gefundene Log-Ordner: {len(dirs_with_files)}")
        print(f"Gesamt Log-Dateien: {len(all_log_files)}")
        print(f"Gesamt Gr√∂√üe: {total_size / (1024*1024):.1f}MB")
        print()

        # Zeige Details pro Ordner
        for dir_name, files in dirs_with_files.items():
            dir_size = sum(f['size'] for f in files)
            print(f"üìÅ {dir_name}: {len(files)} Dateien ({dir_size / 1024:.1f}KB)")

        confirm = input(f"\nWirklich ALLE {len(all_log_files)} Log-Dateien l√∂schen? [y/N]: ").strip().lower()

        if confirm != 'y':
            print("‚ùå L√∂schung abgebrochen.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        # L√∂sche alle Log-Dateien
        deleted_count = 0
        deleted_size = 0

        for log_file in all_log_files:
            try:
                if os.path.exists(log_file['path']):
                    os.remove(log_file['path'])
                    deleted_count += 1
                    deleted_size += log_file['size']
            except Exception as e:
                print(f"‚ö†Ô∏è  Fehler beim L√∂schen von {log_file['name']}: {e}")

        # L√∂sche leere Log-Ordner (optional)
        empty_dirs_removed = 0
        for log_dir in log_directories:
            try:
                if os.path.exists(log_dir) and not os.listdir(log_dir):
                    os.rmdir(log_dir)
                    empty_dirs_removed += 1
                    print(f"üìÅ Leerer Ordner entfernt: {log_dir}")
            except Exception:
                pass  # Ordner nicht leer oder andere Fehler ignorieren

        print(f"‚úÖ {deleted_count}/{len(all_log_files)} Log-Dateien gel√∂scht ({deleted_size / (1024*1024):.1f}MB).")
        if empty_dirs_removed > 0:
            print(f"üìÅ {empty_dirs_removed} leere Log-Ordner entfernt.")

        input("Dr√ºcke Enter um fortzufahren...")

    def _delete_everything(self):
        """L√∂scht ALLES: Checkpoints, Modelle, Logs und leert alle Ordner komplett."""
        import os
        import shutil

        checkpoints = self.checkpoint_manager.scan_checkpoints()
        models = self._scan_trained_models()

        # Sammle ALLE Log-Informationen (nicht nur checkpoint-related)
        log_directories = [
            "training_logs",
            "LLM_Stuff/training_logs",
            "current_training/logs",
            "logs",
        ]

        all_log_files = []
        total_log_size = 0

        for log_dir in log_directories:
            if os.path.exists(log_dir):
                for item in os.listdir(log_dir):
                    item_path = os.path.join(log_dir, item)
                    if os.path.isfile(item_path):
                        if any(item.endswith(ext) for ext in ['.json', '.log', '.png']):
                            file_size = os.path.getsize(item_path)
                            all_log_files.append(item_path)
                            total_log_size += file_size

        # Sammle alle Ordner die geleert werden
        directories_to_clear = [
            "current_training/checkpoints",
            "trained_models",
            "training_logs",
            "LLM_Stuff/training_logs",
            "current_training/logs",
            "logs",
        ]

        existing_dirs = [d for d in directories_to_clear if os.path.exists(d)]

        total_model_size = sum(model['size'] for model in models)

        print(f"\n‚ö†Ô∏è  KOMPLETTE BEREINIGUNG:")
        print("=" * 50)
        print(f"üìã Checkpoints: {len(checkpoints)}")
        print(f"üéØ Modelle: {len(models)} ({total_model_size:.1f}MB)")
        print(f"üìÑ Log-Dateien: {len(all_log_files)} ({total_log_size / (1024*1024):.1f}MB)")
        print(f"üìÅ Ordner zu leeren: {len(existing_dirs)}")
        print()
        print("üóÇÔ∏è  BETROFFENE ORDNER:")
        for dir_name in existing_dirs:
            if os.path.exists(dir_name):
                item_count = len([f for f in os.listdir(dir_name) if os.path.isfile(os.path.join(dir_name, f))])
                print(f"   ‚Ä¢ {dir_name} ({item_count} Dateien)")

        print("\n‚ö†Ô∏è  WARNUNG: Dies l√∂scht ALLES und leert alle Training-Ordner!")
        confirm = input("Wirklich KOMPLETTE BEREINIGUNG durchf√ºhren? [y/N]: ").strip().lower()

        if confirm != 'y':
            print("‚ùå Bereinigung abgebrochen.")
            input("Dr√ºcke Enter um fortzufahren...")
            return

        print("\nüóëÔ∏è  KOMPLETTE BEREINIGUNG GESTARTET:")
        print("=" * 50)

        # 1. L√∂sche alle Ordner komplett und erstelle sie neu
        for dir_name in existing_dirs:
            try:
                if os.path.exists(dir_name):
                    print(f"üóÇÔ∏è  Leere Ordner: {dir_name}")
                    shutil.rmtree(dir_name)
                    os.makedirs(dir_name, exist_ok=True)
                    print(f"‚úÖ Ordner geleert und neu erstellt: {dir_name}")
            except Exception as e:
                print(f"‚ö†Ô∏è  Fehler bei {dir_name}: {e}")

        # 2. Stelle sicher, dass wichtige Ordner existieren
        essential_dirs = [
            "current_training/checkpoints",
            "trained_models",
            "training_logs",
        ]

        for dir_name in essential_dirs:
            os.makedirs(dir_name, exist_ok=True)

        print("\n‚úÖ KOMPLETTE BEREINIGUNG ABGESCHLOSSEN!")
        print("=" * 50)
        print("üéØ Alle Checkpoints gel√∂scht")
        print("üéØ Alle Modelle gel√∂scht")
        print("üéØ Alle Logs gel√∂scht")
        print("üéØ Alle Ordner geleert und neu erstellt")
        print("üéØ System bereit f√ºr neues Training")

        input("\nDr√ºcke Enter um fortzufahren...")
    
    def handle_training_mode_selection(self) -> Dict:
        """Hauptfunktion f√ºr Training-Modus-Auswahl mit Log-Bereinigung."""
        print("\nüöÄ TRAINING MODE SELECTION")
        print("=" * 50)

        # Scanne verf√ºgbare Checkpoints
        checkpoints = self.checkpoint_manager.scan_checkpoints()

        if not checkpoints:
            print("Keine Checkpoints gefunden. Starte neues Training.")
            model_name = self.get_model_name_from_user()

            # Bereinige Logs f√ºr neues Modell (falls welche existieren)
            print(f"\nüßπ Bereinige verwaiste Logs f√ºr: {model_name}")
            self.cleanup_orphaned_logs(model_name)

            return {
                'mode': 'new',
                'model_name': model_name
            }

        # Zeige Checkpoint-Menu
        selected_checkpoint = self.display_checkpoint_menu(checkpoints)

        if selected_checkpoint is None:
            # Neues Training - Cache ausw√§hlen
            cache_info = self.select_cache_for_new_training()
            model_name = self.get_model_name_from_user()
            return {
                'mode': 'new',
                'model_name': model_name,
                'cache_info': cache_info
            }
        else:
            # Checkpoint fortsetzen
            print(f"\n‚úÖ Checkpoint ausgew√§hlt: {selected_checkpoint['filename']}")

            # Bereinige Logs f√ºr Checkpoint-Resume (vor Pipeline!)
            model_name = selected_checkpoint['model_name']
            print(f"\nüßπ Bereinige verwaiste Logs f√ºr: {model_name}")
            self.cleanup_orphaned_logs(model_name)

            # Checkpoint fortsetzen - Cache aus Checkpoint-Info extrahieren
            cache_info = self.extract_cache_from_checkpoint(selected_checkpoint)
            return {
                'mode': 'checkpoint',
                'checkpoint_info': selected_checkpoint,
                'cache_info': cache_info
            }
    
    def cleanup_orphaned_logs(self, model_name: str):
        """Bereinigt Logs ohne korrespondierenden Checkpoint."""
        print(f"üßπ Bereinige verwaiste Logs f√ºr Modell: {model_name}")

        # Scanne Checkpoints f√ºr dieses Modell
        checkpoints = self.checkpoint_manager.scan_checkpoints()
        checkpoint_runs = set()
        for cp in checkpoints:
            if cp['model_name'] == model_name:
                checkpoint_runs.add(cp['run_id'])

        # Scanne Log-Dateien
        log_dir = "training_logs"
        if not os.path.exists(log_dir):
            return

        deleted_count = 0
        for filename in os.listdir(log_dir):
            if filename.startswith(f"{model_name}_run_") and filename.endswith(".json"):
                try:
                    # Extrahiere Run-ID aus Log-Datei
                    run_part = filename.replace(f"{model_name}_run_", "").replace(".json", "").replace("_summary", "")
                    log_run_id = int(run_part)

                    # L√∂sche Log wenn kein korrespondierender Checkpoint existiert
                    if log_run_id not in checkpoint_runs:
                        log_path = os.path.join(log_dir, filename)
                        try:
                            os.remove(log_path)
                            print(f"   üóëÔ∏è  Gel√∂scht: {filename} (kein Checkpoint f√ºr Run {log_run_id})")
                            deleted_count += 1
                        except OSError as e:
                            print(f"   ‚ö†Ô∏è  Konnte {filename} nicht l√∂schen: {e}")

                except ValueError:
                    continue

        if deleted_count == 0:
            print("   ‚úÖ Keine verwaisten Logs gefunden")
        else:
            print(f"   ‚úÖ {deleted_count} verwaiste Log-Dateien bereinigt")

    def select_cache_for_new_training(self):
        """Auswahl des Caches f√ºr neues Training."""
        from ..utils.cache_registry import load_cache_registry, display_cache_menu

        print(f"\nüì¶ CACHE AUSWAHL F√úR NEUES TRAINING")
        print("=" * 50)

        # Lade verf√ºgbare Caches
        caches = load_cache_registry()

        if not caches:
            print("‚ùå Keine Caches verf√ºgbar!")
            print("Erstelle zuerst einen Cache mit:")
            print("python scripts/create_packed_cache.py")
            return None

        # Zeige Cache-Menu
        selected_cache = display_cache_menu(caches)

        if selected_cache:
            print(f"‚úÖ Cache ausgew√§hlt: {selected_cache['dataset_name']} (seq_len: {selected_cache['sequence_length']})")
            return selected_cache
        else:
            print("‚ùå Kein Cache ausgew√§hlt")
            return None

    def extract_cache_from_checkpoint(self, checkpoint_info):
        """Extrahiert Cache-Info aus Checkpoint mit robustem Fallback."""
        import torch
        from ..utils.cache_registry import load_cache_registry, find_cache_by_sequence_length

        try:
            # Lade Checkpoint um Cache-Info zu extrahieren
            checkpoint = torch.load(checkpoint_info['filepath'], map_location='cpu', weights_only=False)

            # Neue Checkpoints haben cache_info
            if 'cache_info' in checkpoint:
                cache_info = checkpoint['cache_info']
                print(f"üì¶ Cache aus Checkpoint: {cache_info['dataset_name']} (seq_len: {cache_info['sequence_length']})")

                # Validiere dass Cache noch existiert und aktualisiere Gr√∂√üe
                from ..utils.cache_registry import validate_cache, load_cache_registry
                print(f"üîç Validating cache: {cache_info['dataset_name']} at {cache_info.get('path', 'unknown')}")
                if validate_cache(cache_info):
                    # FIXED: Update cache info with current size (for expanded datasets)
                    current_caches = load_cache_registry()
                    for current_cache in current_caches:
                        if (current_cache['dataset_name'] == cache_info['dataset_name'] and
                            current_cache['sequence_length'] == cache_info['sequence_length']):
                            old_sequences = cache_info.get('total_sequences', 0)
                            new_sequences = current_cache.get('total_sequences', 0)

                            if new_sequences > old_sequences:
                                print(f"üìà Dataset expanded: {old_sequences:,} ‚Üí {new_sequences:,} sequences")
                                cache_info['total_sequences'] = new_sequences
                                cache_info['path'] = current_cache['path']  # Update path too

                            break

                    print(f"‚úÖ Cache validation successful")
                    return cache_info
                else:
                    print(f"‚ö†Ô∏è  Cache validation failed, suche Alternative...")

            # Fallback 1: Aus training_config sequence_length ableiten
            if 'training_config' in checkpoint:
                training_config = checkpoint['training_config']
                seq_len = training_config.get('sequence_length', 512)

                cache = find_cache_by_sequence_length(seq_len)
                if cache:
                    print(f"üì¶ Cache gefunden f√ºr seq_len {seq_len}: {cache['dataset_name']}")
                    return cache

            # Fallback 2: Ersten verf√ºgbaren Cache verwenden
            caches = load_cache_registry()
            if caches:
                cache = caches[0]
                print(f"üì¶ Fallback Cache: {cache['dataset_name']} (seq_len: {cache['sequence_length']})")
                return cache

            # Fallback 3: Hardcoded Default
            print("‚ö†Ô∏è  Kein Cache gefunden, verwende Fallback")
            return {
                'dataset_name': 'FineWeb',
                'sequence_length': 512,
                'path': 'cache/packed_sequences/512/FineWeb',
                'total_sequences': 352217
            }

        except Exception as e:
            print(f"‚ö†Ô∏è  Fehler beim Extrahieren der Cache-Info: {e}")

            # Ultimate Fallback
            caches = load_cache_registry()
            if caches:
                return caches[0]

            return {
                'dataset_name': 'FineWeb',
                'sequence_length': 512,
                'path': 'cache/packed_sequences/512/FineWeb',
                'total_sequences': 352217
            }


def get_next_run_id(model_name: str) -> int:
    """Ermittelt n√§chste Run-ID f√ºr ein Modell basierend auf Checkpoints."""
    checkpoint_manager = CheckpointManager()
    checkpoints = checkpoint_manager.scan_checkpoints()

    # Finde h√∂chste Run-ID f√ºr dieses Modell
    max_run_id = 0
    for cp in checkpoints:
        if cp['model_name'] == model_name:
            max_run_id = max(max_run_id, cp['run_id'])

    return max_run_id + 1


def handle_training_mode_selection() -> Dict:
    """Convenience function f√ºr Training Mode Selection."""
    training_state = TrainingState()
    return training_state.handle_training_mode_selection()


def load_checkpoint_for_training(checkpoint_info: Dict):
    """L√§dt Checkpoint f√ºr Training-Fortsetzung."""
    checkpoint_manager = CheckpointManager()
    return checkpoint_manager.load_checkpoint(checkpoint_info)
